{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from itertools import cycle\n",
    "import torch\n",
    "import typing\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset, random_split\n",
    "import numpy as np\n",
    "from encoder import Encoder, create_encoder\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 512])\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self, path: str, encoder: Encoder, seq_len: int = 512\n",
    "    ) -> None:\n",
    "        self.seq_len = seq_len\n",
    "        self.encoder = encoder\n",
    "        self.path = path\n",
    "\n",
    "    def read_file(self) -> Generator:\n",
    "        \"\"\"Reads the file and yields each character.\"\"\"\n",
    "        with open(self.path, \"r\") as f:\n",
    "            for line in f:\n",
    "                yield from line.strip(\"\\n\")\n",
    "        \n",
    "\n",
    "    def __iter__(self) -> Generator:\n",
    "        \"\"\"\n",
    "        Stream characters from file and encode them. \n",
    "        When the sequence reaches the desired length, yield it.\n",
    "        \"\"\"\n",
    "        sequence = []\n",
    "        for char in self.read_file():\n",
    "            tokens = self.encoder.encode(char)\n",
    "            for token in tokens:\n",
    "                if len(sequence) == self.seq_len:\n",
    "                    yield sequence\n",
    "                    sequence = []\n",
    "                sequence.append(token)\n",
    "\n",
    "def get_dataloaders(\n",
    "    batch_size=128, \n",
    "    seq_len=512, \n",
    "    train_path=\"./data/gutenberg_train.txt\", \n",
    "    test_path=\"./data/gutenberg_test.txt\"\n",
    ") -> typing.Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"Create the test and validation dataloaders\"\"\"\n",
    "\n",
    "    encoder = create_encoder(\"./data/pg16457.txt\")\n",
    "    train_dataset = TextDataset(train_path, encoder, seq_len=seq_len)\n",
    "    test_dataset = TextDataset(test_path, encoder, seq_len=seq_len)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, collate_fn=lambda x: torch.tensor(x)\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, collate_fn=lambda x: torch.tensor(x)\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6c9e77d69fdc734b0a4e50053fe601397809ac29df62e5af5373f8044db8c53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
